{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Part One: Working with Student Grade Data**"
      ],
      "metadata": {
        "id": "phq9OhhWwUbn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Load the Student Grade Files**"
      ],
      "metadata": {
        "id": "U04nIjSbvXbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load each grade file as string data\n",
        "hwd = np.loadtxt(\"./lab2-hw.txt\", dtype=str)\n",
        "testd = np.loadtxt(\"./lab2-test.txt\", dtype=str)\n",
        "quizd = np.loadtxt(\"./lab2-quiz.txt\", dtype=str)\n",
        "projd = np.loadtxt(\"./lab2-project.txt\", dtype=str)\n"
      ],
      "metadata": {
        "id": "uk5xJGcPuFHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Convert Strings to Floats**"
      ],
      "metadata": {
        "id": "y5dThthnvalc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exclude headers and names, convert scores to floats\n",
        "hw1 = (hwd[1:, 1:]).astype(float)\n",
        "test1 = (testd[1:, 1:]).astype(float)\n",
        "quiz1 = (quizd[1:, 1:]).astype(float)\n",
        "proj1 = (projd[1:, 1:]).astype(float)\n"
      ],
      "metadata": {
        "id": "wkjDW7rlwGUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Compute Averages for Each Category**"
      ],
      "metadata": {
        "id": "3ZcMNr7rvtwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the average score for each student\n",
        "hw_ave = np.average(hw1, axis=1)\n",
        "test_ave = np.average(test1, axis=1)\n",
        "quiz_ave = np.average(quiz1, axis=1)\n",
        "proj_ave = np.average(proj1, axis=1)\n"
      ],
      "metadata": {
        "id": "NBlPaGaf5nGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Normalize Scores to a 100-Point Scale**"
      ],
      "metadata": {
        "id": "5D2cY0oWvz3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale all scores to a percentage basis (out of 100)\n",
        "hw_w = hw_ave * (100/50)    # Homework out of 50 points\n",
        "test_w = test_ave * (100/100)  # Tests already out of 100\n",
        "quiz_w = quiz_ave * (100/10)   # Quizzes out of 10 points\n",
        "proj_w = proj_ave * (100/100)  # Project already out of 100\n"
      ],
      "metadata": {
        "id": "SmNyRh_c6n37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5: Build the Grade Matrix**"
      ],
      "metadata": {
        "id": "sMa1ut5iv4Vr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all categories into a single matrix\n",
        "grades = np.column_stack((hw_w, test_w, quiz_w, proj_w))\n",
        "print(grades)  # Display the matrix of all student scores\n"
      ],
      "metadata": {
        "id": "TlxMU2k17RIp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0a48421-89b7-4baa-8b9e-8b8b3d8142c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[92.  94.  90.  90. ]\n",
            " [80.4 90.  88.  95. ]\n",
            " [73.2 83.  80.  85. ]\n",
            " [83.6 87.5 94.  71. ]\n",
            " [88.4 74.5 88.  82. ]\n",
            " [71.2 80.  76.  70. ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6: Define the Weight Vector**"
      ],
      "metadata": {
        "id": "kuYrpv8swH7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Weighting for final grade calculation\n",
        "# Homework 30%, Tests 40%, Quizzes 10%, Project 20%\n",
        "wgt = [0.3, 0.4, 0.1, 0.2]\n"
      ],
      "metadata": {
        "id": "l-04J0lO7dtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 7: Apply Matrix Multiplication**"
      ],
      "metadata": {
        "id": "BAWoOaYvwLlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiply grade matrix by weight vector to compute final grades\n",
        "final_grade = np.matmul(grades, wgt)\n",
        "print(final_grade)  # Display the final grades for all students\n"
      ],
      "metadata": {
        "id": "GyRuMxIO7uW_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c51064e9-a192-45c4-bbb5-45ab65d111a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[92.2  87.92 80.16 83.68 81.52 74.96]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bonus Step: Build a Final Grades Table**"
      ],
      "metadata": {
        "id": "ixRe-oHzwPbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assume student names are in the first column of hwd\n",
        "student_names = hwd[1:, 0]\n",
        "\n",
        "# Build a DataFrame with all scores and final grade\n",
        "df_grades = pd.DataFrame({\n",
        "    \"Student\": student_names,\n",
        "    \"Homework (%)\": hw_w.round(2),\n",
        "    \"Tests (%)\": test_w.round(2),\n",
        "    \"Quizzes (%)\": quiz_w.round(2),\n",
        "    \"Project (%)\": proj_w.round(2),\n",
        "    \"Final Grade\": final_grade.round(2)\n",
        "})\n",
        "\n",
        "print(df_grades)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoGjTc362ToI",
        "outputId": "6571652a-ed3b-48ef-9329-e2ad243c3b94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Student  Homework (%)  Tests (%)  Quizzes (%)  Project (%)  Final Grade\n",
            "0       A          92.0       94.0         90.0         90.0        92.20\n",
            "1       B          80.4       90.0         88.0         95.0        87.92\n",
            "2       C          73.2       83.0         80.0         85.0        80.16\n",
            "3       D          83.6       87.5         94.0         71.0        83.68\n",
            "4       E          88.4       74.5         88.0         82.0        81.52\n",
            "5       F          71.2       80.0         76.0         70.0        74.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part Two: Cleaning Goodreads Data**"
      ],
      "metadata": {
        "id": "RVfrz0aWwa5w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Load the Dataset**"
      ],
      "metadata": {
        "id": "dfiYQOcQwe-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Goodreads dataset from Pickle file\n",
        "df = pd.read_pickle('lab2-T2-data.pkl')"
      ],
      "metadata": {
        "id": "BsILka1MFd_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Explore the Data**"
      ],
      "metadata": {
        "id": "0b4ASLlywhyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display first few rows\n",
        "df.head(3)\n",
        "\n",
        "# Get dataset information: shape, column names, data types\n",
        "df.info()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVXgxIuXGUWz",
        "outputId": "2c19d020-7dcb-4da3-f7a1-f746f40df1ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 671 entries, 0 to 670\n",
            "Data columns (total 14 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   title           671 non-null    object\n",
            " 1   subtitle        218 non-null    object\n",
            " 2   series          122 non-null    object\n",
            " 3   author          671 non-null    object\n",
            " 4   my_rating       640 non-null    object\n",
            " 5   avg_rating      671 non-null    object\n",
            " 6   publisher       669 non-null    object\n",
            " 7   binding         671 non-null    object\n",
            " 8   pages           671 non-null    int64 \n",
            " 9   year_published  671 non-null    object\n",
            " 10  month_read      671 non-null    object\n",
            " 11  month_read_num  671 non-null    int64 \n",
            " 12  year_read       671 non-null    int64 \n",
            " 13  bookshelf       671 non-null    object\n",
            "dtypes: int64(3), object(11)\n",
            "memory usage: 73.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Check for Missing Values**"
      ],
      "metadata": {
        "id": "z1zGm6Rwwkob"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b99ed688",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a8e30cd-67a6-4d55-f651-fbd4b64e5adb"
      },
      "source": [
        "# Count missing values in a single column\n",
        "df['my_rating'].isnull().sum()\n",
        "\n",
        "# Count missing values for all columns\n",
        "for col in df.columns:\n",
        "    print(col, df[col].isnull().sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "title 0\n",
            "subtitle 453\n",
            "series 549\n",
            "author 0\n",
            "my_rating 31\n",
            "avg_rating 0\n",
            "publisher 2\n",
            "binding 0\n",
            "pages 0\n",
            "year_published 0\n",
            "month_read 0\n",
            "month_read_num 0\n",
            "year_read 0\n",
            "bookshelf 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Drop Rows Missing Critical Fields**"
      ],
      "metadata": {
        "id": "ultBsJS5woPV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "208670d8"
      },
      "source": [
        "# Remove rows missing ratings or publishing year\n",
        "df1 = df.dropna(subset=['my_rating', 'avg_rating', 'year_published'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5: Missing Non-Critical Fields**"
      ],
      "metadata": {
        "id": "H86zcEwywvdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace NaN with blank strings in text fields\n",
        "df1.loc[:, ['subtitle','series','publisher']] = df1[['subtitle','series','publisher']].fillna(' ')"
      ],
      "metadata": {
        "id": "2v8RnMFyM95-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6: Remove Invalid Records**"
      ],
      "metadata": {
        "id": "in8s5SERw0I6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with negative years or ratings outside 0–5\n",
        "df1 = df1[(df1['year_published'] > 0) &\n",
        "          (df1['avg_rating'] >= 0) & (df1['avg_rating'] <= 5)]\n"
      ],
      "metadata": {
        "id": "IGufhz0MNCKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 7: Group Data by Author**"
      ],
      "metadata": {
        "id": "tfLlrMpxw3jh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group books by author\n",
        "group_author = df1.groupby('author')\n",
        "\n",
        "# Count how many books each author published\n",
        "df_num = group_author['author'].count()\n",
        "\n",
        "# Find the most prolific author\n",
        "max_count = 0\n",
        "max_author = ''\n",
        "for author in df_num.index:\n",
        "    if df_num[author] > max_count:\n",
        "        max_count = df_num[author]\n",
        "        max_author = author\n",
        "\n",
        "print(max_author, max_count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBOCpZVtNFA_",
        "outputId": "a5dcefdc-6e10-4571-d712-490262c6f551"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grisham, John 22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 8: Display Books by Most Prolific Author**"
      ],
      "metadata": {
        "id": "_5ctifKmw6eX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print all books and years for the top author\n",
        "for author, subset in df1.groupby('author'):\n",
        "    if author == max_author:\n",
        "        print(author)\n",
        "        for index, row in subset.iterrows():\n",
        "            print(row['title'], row['year_published'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqVCuKbNNf_L",
        "outputId": "4a8072e5-84e5-4f69-d6c7-1957c6f168eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grisham, John\n",
            "A Time to Kill 1989\n",
            "Calico Joe 2012\n",
            "Ford County 2008\n",
            "Playing for Pizza 2007\n",
            "Rogue Lawyer 2015\n",
            "Sycamore Row 2013\n",
            "The Associate 2009\n",
            "The Brethren 2000\n",
            "The Broker 2005\n",
            "The Chamber 1994\n",
            "The Confession 2010\n",
            "The King of Torts 2003\n",
            "The Last Juror 2004\n",
            "The Litigators 2011\n",
            "The Partner 1997\n",
            "The Racketeer 2012\n",
            "The Rooster Bar 2018\n",
            "The Street Lawyer 1998\n",
            "The Summons 2002\n",
            "The Testament 1999\n",
            "The Whistler 2016\n",
            "Theodore Boone 2010\n"
          ]
        }
      ]
    }
  ]
}